{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Petros Polyhchronis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset overivew\n",
    "\n",
    "\n",
    "| Column ID   | Column Name     | Description |\n",
    "| ----------- | -----------     | ----------- |\n",
    "|     1       | Year            | =2007       |\n",
    "|     2       | Month       | 1-31        |\n",
    "|     3       | DayofMonth  | 1-12        |\n",
    "|     4       | DayOfWeek   | (Monday) - 7 (Sunday)        |\n",
    "|     5       | DepTime     | actual departure time (local, hhmm)        |\n",
    "|     6       | CRSDepTime  | scheduled departure time (local, hhmm)        |\n",
    "|     7       | ArrTime     | actual arrival time (local, hhmm)        |\n",
    "|     8       | CRSArrTime  | scheduled arrival time (local, hhmm)        |\n",
    "|     9       | UniqueCarrier   | unique carrier code       |\n",
    "|     10      | FlightNum   | flight number        |\n",
    "|     11      | TailNum   | plane tail number        |\n",
    "|     12      | ActualElapsedTime   | in minutes        |\n",
    "|     13      | CRSElapsedTime   | in minutes        |\n",
    "|     14      | AirTime        | in minutes        |\n",
    "|     15      | ArrDelay     | arrival delay, in minutes        |\n",
    "|     16      | DepDelay departure   | delay, in minutes        |\n",
    "|     17      | Origin   |  origin  IATA airport code        |\n",
    "|     18      | Dest   | destination IATA airport code        |\n",
    "|     19      | Distance    | in miles        |\n",
    "|     20      | TaxiIn   |taxi in time, in minutes        |\n",
    "|     21      | TaxiOut   | taxi out time in minutes        |\n",
    "|     22      | Cancelled    | was the flight cancelled?       |\n",
    "|     23      | CancellationCode   | reason for cancellation (A = carrier, B = weather, C =\n",
    "NAS, D = security)        |\n",
    "|     24      | Diverted    | 1 = yes, 0 = no        |\n",
    "|     25      | CarrierDelay   | in minutes        |\n",
    "|     26      | WeatherDelay    | in minutes        |\n",
    "|     27      | NASDelay    | in minutes        |\n",
    "|     28      | SecurityDelay   |in minutes        |\n",
    "|     29      | LateAircraftDelay   |in minutes        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Init pyspark\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "# Init sparksql -- Only used to format the output nicely!\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "rows = sc.textFile(\"/air_transit_2007.csv\")\n",
    "data = rows.map(lambda line: line.split(\",\"))\n",
    "# data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from pyspark.sql.functions import col\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "source": [
    "# Sample Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+\n",
      "|Sched. Departure|Destination|\n",
      "+----------------+-----------+\n",
      "|            1455|        CLE|\n",
      "|            1840|        CLE|\n",
      "|             659|        CLE|\n",
      "|            1750|        EWR|\n",
      "|             630|        EWR|\n",
      "|            1650|        EWR|\n",
      "|            1255|        EWR|\n",
      "|            1025|        EWR|\n",
      "|            1034|        IAD|\n",
      "|            1607|        IAD|\n",
      "|            1006|        ORD|\n",
      "|             600|        ORD|\n",
      "|            2000|        ORD|\n",
      "|             628|        JFK|\n",
      "|             638|        CVG|\n",
      "|            1100|        CVG|\n",
      "|            1141|        JFK|\n",
      "|            1530|        JFK|\n",
      "|            1700|        JFK|\n",
      "|            1827|        CVG|\n",
      "|             720|        ORD|\n",
      "|            1725|        ORD|\n",
      "|             800|        CLT|\n",
      "|             720|        PHL|\n",
      "|             600|        ATL|\n",
      "|            1521|        ATL|\n",
      "|            1730|        ATL|\n",
      "|            1236|        ATL|\n",
      "|             935|        ATL|\n",
      "|             600|        ATL|\n",
      "|            1145|        ATL|\n",
      "|             700|        BWI|\n",
      "|            1336|        BWI|\n",
      "|            1759|        BWI|\n",
      "|             800|        MCO|\n",
      "|            1231|        MCO|\n",
      "|             904|        TPA|\n",
      "|             630|        DFW|\n",
      "|            1225|        ORD|\n",
      "|             710|        ORD|\n",
      "|            1630|        ORD|\n",
      "|            1905|        ORD|\n",
      "|             600|        DTW|\n",
      "|             930|        DTW|\n",
      "|            1540|        DTW|\n",
      "|             640|        MSP|\n",
      "|            1250|        DTW|\n",
      "|            1115|        JFK|\n",
      "|            1930|        JFK|\n",
      "|             755|        JFK|\n",
      "|            1710|        JFK|\n",
      "|             600|        JFK|\n",
      "|             750|        ATL|\n",
      "+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_results = data.filter(lambda r: (r[16]=='ROC'and r[1]=='3' and r[2]=='12')) \\\n",
    "    .map(lambda r: (r[5] , r[17])) \\\n",
    "    .collect()\n",
    "\n",
    "#format nicely!\n",
    "sqlContext.createDataFrame(sample_results, ['Sched. Departure', 'Destination']).show(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some  additional tools to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add # to perform addition within reducyByKey()\n",
    "from pyspark.sql.functions import col # to preview selected rows fromd dataframes\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Inspection and Filtering\n",
    "\n",
    "In what follows, we lay out a few tools created to facilitate the data inspection and filtering process. In particular, we are finding all non-arithmetic entries in numerical columns using 2 custom functions. The first helper function is `distinct(x)` and the second is called `find_non_arithmetics(x)`. The first creates a string of all distict values for each column and the second one finds all non-arithmetic characters within that string. Both functions are used within a map-reduce context, where each column is a key. These results will help us irrelevant/NA values during our calculations throughout the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical columns: All columns except *UniqueCarrier*, *Origin*, *Dest*, *CancellationCode*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct(x,y):\n",
    "    if y in x:\n",
    "        return x\n",
    "    else:\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_arithmetics(x):\n",
    "    import re\n",
    "    pattern= r'\\D+'\n",
    "    words = re.findall(pattern,x[1])\n",
    "    words = list(set(words))\n",
    "    return (x[0], words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = data.flatMap(lambda x:(\n",
    "                               (('Month')            , x[1]),\n",
    "                               (('DayofMonth')       , x[2]),\n",
    "                               (('DayOfWeek')        , x[3]),\n",
    "                               (('DepTime')          , x[4]),\n",
    "                               (('CRSDepTime')       , x[5]),\n",
    "                               (('ArrTime')          , x[6]),\n",
    "                               (('CRSArrTime')       , x[7]),\n",
    "                               (('FlightNum')        , x[9]),\n",
    "                               (('TailNum')          , x[10]),\n",
    "                               (('ActualElapsedTime'), x[11]),\n",
    "                               (('CRSElapsedTime')   , x[12]),\n",
    "                               (('AirTime')          , x[13]),\n",
    "                               (('ArrDelay')         , x[14]),\n",
    "                               (('DepDelay')         , x[15]),\n",
    "                               (('Distance')         , x[18]),\n",
    "                               (('TaxiIn')           , x[19]),\n",
    "                               (('TaxiOut')          , x[20]),\n",
    "                               (('Cancelled')        , x[21]),\n",
    "                               (('Diverted')         , x[23]),\n",
    "                               (('CarrierDelay')     , x[24]),\n",
    "                               (('WeatherDelay')     , x[25]),\n",
    "                               (('NASDelay')         , x[26]),\n",
    "                               (('SecurityDelay')    , x[27]),\n",
    "                               (('LateAircraftDelay'), x[28])))\\\n",
    "                      .reduceByKey(distinct)\\\n",
    "                      .map(find_non_arithmetics)\\\n",
    "                      .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------------+\n",
      "|      Column Name|Non-arithmetic Values|\n",
      "+-----------------+---------------------+\n",
      "|     WeatherDelay|       [WeatherDelay]|\n",
      "|   CRSElapsedTime| [-, NA, CRSElapse...|\n",
      "|        FlightNum|          [FlightNum]|\n",
      "|ActualElapsedTime| [NA, ActualElapse...|\n",
      "|          TaxiOut|            [TaxiOut]|\n",
      "|          ArrTime|        [NA, ArrTime]|\n",
      "|         ArrDelay| [NA-, NA, ArrDela...|\n",
      "|         NASDelay|           [NASDelay]|\n",
      "|    SecurityDelay|      [SecurityDelay]|\n",
      "|       CRSDepTime|         [CRSDepTime]|\n",
      "|       CRSArrTime|         [CRSArrTime]|\n",
      "|         Distance|           [Distance]|\n",
      "|           TaxiIn|             [TaxiIn]|\n",
      "|            Month|              [Month]|\n",
      "|LateAircraftDelay|  [LateAircraftDelay]|\n",
      "|         Diverted|           [Diverted]|\n",
      "|         DepDelay| [-, NA-, NA, DepD...|\n",
      "|        Cancelled|          [Cancelled]|\n",
      "|        DayOfWeek|          [DayOfWeek]|\n",
      "|          AirTime|        [AirTime, NA]|\n",
      "|       DayofMonth|         [DayofMonth]|\n",
      "|          DepTime|        [NA, DepTime]|\n",
      "|          TailNum| [EEAAN, CTAAN, WD...|\n",
      "|     CarrierDelay|       [CarrierDelay]|\n",
      "+-----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filters = sqlContext.createDataFrame(filters, ['Column Name', 'Non-arithmetic Values'])\n",
    "df_filters.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each exercise, we will be selecting and printing the revelant columns from this dataset to inspect whether there are 'NA' values or negative values, indicated by the existance of hyphens in the non-arithmetic values list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to that, we observe that each column entails its column name as a non-arithmetic value. This indicates that there is probably a row that contains the column names as values. We can verify this as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'TailNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']]\n"
     ]
    }
   ],
   "source": [
    "print(data.filter(lambda x: x[1]== 'Month').collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one line in the dataset containing the names of the columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Methodology\n",
    "We follow the general concept of Map & Reduce as discussed in class. The two main players are Map and Recude functions. The mapping task reduces to establishhing what the (key, value) pairs for each row should be. By and large, the key is gonna be the attribute that we want to aggregate our results by, and the value is gonna a tuple of attributes, which in the interest of computational efficiency should contain as little information as possible in order to reach our analysis goals. Next, the Reduce step is comprised of finding what the aggregation function should be based on our analytical objectives (e.g., count, sum, etc.). These two actions form the cornerstone approach for all questions. On top of that, and as mentioned in the assignment description, filtering the data such that only the relevant rows are included in the processing is also undertaken as a first step to improve efficiency and reduce computational time. Finally, we format our results in (sorted) dataframes to ensure readibility and ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Q1 : Compute the total number of records.\n",
    "\n",
    "There are various ways to count the number of records. We can use .count() directly, but I prefer to do it manually using the map and reduce functions. The steps are as follows:\n",
    " 1. Filter out the row containing the column names using `.filter()`.\n",
    " 2. Map each row to the value of 1 (as little data as possible) using `.map()`\n",
    " 3. Use the `.reduce()` function to sum up the 1s. \n",
    " \n",
    "*Note:* We cannot use `.reduceByKey()` here since each row is mapped to a single number (1), which is the key as well. Thus if we use `.reduceByKey()`, the function will automatically extract the first element from the tuple and nothing will be left to add. When using the `.reduce()` function we can define any element of the full tuple and thus it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7453215\n"
     ]
    }
   ],
   "source": [
    "number_of_records = data.filter(lambda x: x[1]!='Month')\\\n",
    "                        .map(lambda r: 1) \\\n",
    "                        .reduce(lambda x, y: x+y)\n",
    "\n",
    "print(number_of_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1 ANSWER: There are 7,453,215 recorded flights in the document.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7453215\n"
     ]
    }
   ],
   "source": [
    "number_of_records = data.filter(lambda x: x[1]!='Month')\\\n",
    "                        .count()\n",
    "\n",
    "print(number_of_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 : Find total number of operated flights per month, sorted by the month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we make use of the columns:\n",
    "- *Month* (column 2)\n",
    "- *Cancelled* (column 22)\n",
    "\n",
    "We inspect what non-arithmetic values exist in the columns to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+\n",
      "|Column Name|Non-arithmetic Values|\n",
      "+-----------+---------------------+\n",
      "|      Month|              [Month]|\n",
      "|  Cancelled|          [Cancelled]|\n",
      "+-----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filters.filter(col('Column Name').isin(['Month', 'Cancelled'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- there are no negative numbers (no hyphens)\n",
    "- no NA entries for the columns *Month* and *Cancelled*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Assumptions and Code Steps:\n",
    "\n",
    "*Assumptions*\n",
    "- Cancelled flights are not considered as operated since they never took place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Code*\n",
    "\n",
    "1. **Filter**: Discard all cancelled flights using `.filter()`. Condition: `x[21] =='0'`.\n",
    "2. **Map**: We map over tuples and create key-value pairs (Key= Month, value=1) using `.map()`. Our goal being to simply count the realized flights, we discard all other attributes to improve efficiency (less data to work with). Additionally, we have converted the string values to integer ones using `int()`.\n",
    " 3. **Reduce**: We reduce the results by aggregating (here: summing) the 1s for each separate key (=month) using `reduceByKey()` and the `add()` function (libary:operator). Alternatively, we can also use `lambda x,y: x+y` for the summation\n",
    " 4.  **Sorting**: We sort by key(=month) in ascending order (default value) using `.sortByKey()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_month = data.filter(lambda x: x[21] =='0') \\\n",
    "                       .map(lambda x: (int(x[1]), 1)) \\\n",
    "                       .reduceByKey(add) \\\n",
    "                       .sortByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are then summarised in the following table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Month|Number of Flights|\n",
      "+-----+-----------------+\n",
      "|    1|           605782|\n",
      "|    2|           540139|\n",
      "|    3|           622332|\n",
      "|    4|           603510|\n",
      "|    5|           624768|\n",
      "|    6|           612037|\n",
      "|    7|           635054|\n",
      "|    8|           640984|\n",
      "|    9|           593680|\n",
      "|   10|           622665|\n",
      "|   11|           598870|\n",
      "|   12|           592646|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = sqlContext.createDataFrame(flights_by_month, ['Month', 'Number of Flights']).show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q3 : Find the plane with the highest number of flights. Each plane has a unique TailNum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we make use of the columns:\n",
    "- *TailNum* (column 11)\n",
    "- *Cancelled* (column 22)\n",
    "\n",
    "\n",
    "We only inspect the new columns. i.e. *TailNum*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Non-arithmetic Values=['EEAAN', 'CTAAN', 'WDAAN', 'BPAAN', 'DEAAN', 'WNAAN', 'FFAAN', 'JN', 'YBAAN', 'EMAAN', 'BCN', 'TSAAN', 'UAN', 'SN', 'LRN', 'RN', 'WMAAN', 'YAAAN', 'TKAAN', 'CCAAN', 'AKAAN', 'NWN', 'CN', 'AUN', 'YHAAN', 'XN', 'FRN', 'TDAAN', 'BYAAN', 'ACAAN', 'EUAAN', 'BAAAN', 'KN', 'FAAAN', 'WAAAN', 'YN', 'CLN', 'TGAAN', 'E', 'EVN', 'CYAAN', 'YEAAN', 'DYAAN', 'ADAAN', 'FBAAN', 'ANAAN', 'MJN', 'LEN', 'XMAAN', 'QCN', 'AUAAN', 'DKAAN', 'WVAAN', 'HAN', 'MRN', 'YJAAN', 'NW', 'QXN', 'AYN', 'TN', 'BGN', 'AFAAN', 'FTAAN', 'WXAAN', 'TWN', 'LLN', 'CSAAN', 'YFAAN', 'SWN', 'NRN', 'DGAAN', 'TBN', 'EGAAN', 'FEAAN', 'EJAAN', 'TMAAN', 'JCN', 'DPAAN', 'TFAAN', 'MBN', 'DHAAN', 'DNN', 'GBN', 'WWAAN', 'WYAAN', 'ALNHZOALN', 'XLAAN', 'DFAAN', 'BFAAN', 'FGAAN', 'XXAAN', 'BJAAN', 'EXAAN', 'FRAAN', 'AXN', 'WEAAN', 'PSN', 'CBAAN', 'NCN', 'JSN', 'DAN', 'ALN', 'XGAAN', 'BNAAN', 'XEAAN', 'JHN', 'ASAAN', 'SAN', 'VN', 'CA', 'PCN', 'TEAAN', 'BVAAN', 'JAN', 'DMAAN', 'ENAAN', 'TSN', 'DXAAN', 'MSN', 'DRAAN', 'FLAAN', 'DJAAN', 'FMAAN', 'TUAAN', 'SFN', 'TCAAN', 'YDAAN', 'DWAAN', 'DCAAN', 'DLAAN', 'EVAAN', 'ATAAN', 'WPAAN', 'UCAAN', 'XJAAN', 'XFAAN', 'BXAAN', 'WNN', 'WUAAN', 'ZN', 'WBAAN', 'BWAAN', 'WTAAN', 'XTAAN', 'FPAAN', 'GSN', 'BLAAN', 'HKN', 'UN', 'AWN', 'DCN', 'WSAAN', 'ESAAN', 'CMAAN', 'AGAAN', 'SKN', 'TYAAN', 'WKAAN', 'MAN', 'XYAAN', 'QN', 'YPAAN', 'NBN', 'EDAAN', 'ALAAN', 'JNN', 'BCAAN', 'MHN', 'LTN', 'APAAN', 'BEAAN', 'JLN', 'EKAAN', 'EAN', 'AVAAN', 'ABAAN', 'DDAAN', 'EFAAN', 'AAAAN', 'KRN', 'BSAAN', 'TRN', 'NEN', 'TTAAN', 'XWAAN', 'NC', 'CUAAN', 'YTAAN', 'EBN', 'EHN', 'DBAAN', 'ARN', 'EAAAN', 'EHAAN', 'RGN', 'YSAAN', 'AXAAN', 'TXAAN', 'UWN', 'CGAAN', 'DZN', 'PPN', 'XAAAN', 'XSAAN', 'VJN', 'BRAAN', 'XDAAN', 'FNAAN', 'RJN', 'YUAAN', 'XBAAN', 'XUAAN', 'RWN', 'BTAAN', 'USN', 'WRAAN', 'YNAAN', 'AEN', 'EPAAN', 'MXN', 'BKAAN', 'CPAAN', 'AAN', 'cAN', 'ASN', 'TBAAN', 'CEAAN', 'DSN', 'CNAAN', 'WRN', 'WLAAN', 'LN', 'CDAAN', 'NAN', 'YLAAN', 'TJAAN', 'BN', 'DTAAN', 'PN', 'TLAAN', 'RRN', 'DNAAN', 'UBAAN', 'FKAAN', 'FDAAN', 'AMAAN', 'BMAAN', 'YKAAN', 'MLN', 'BGAAN', 'YVN', 'CFAAN', 'AHAAN', 'ETAAN', 'ECAAN', 'CAN', 'TNAAN', 'JWN', 'ECN', 'XNAAN', 'YGAAN', 'CTN', 'TailNumN', 'HN', 'US', 'EBAAN', 'XPAAN', 'NN', 'CAAAN', 'MN', 'EWAAN', 'YCAAN', 'AYAAN', 'CXAAN', 'BEN', 'XVAAN', 'CVAAN', 'FSAAN', 'HHN', 'DN', 'DAAAN', 'WJAAN', 'CRAAN', 'AJAAN', 'XHAAN', 'XCAAN', 'CKAAN', 'KWN', 'DUAAN', 'BHAAN', 'ARAAN', 'FCAAN', 'ATN', 'AMN', 'YRAAN', 'DVAAN', 'FJN', 'BRN', 'ERAAN', 'XRAAN', 'BDAAN', 'UUN', 'DLN', 'YMAAN', 'PHN', 'RCN', 'LVN', 'XKAAN', 'PGN', 'ABN', 'AEAAN', 'DTN', 'FHAAN', 'MWN', 'MCN', 'CBN', 'CHAAN', 'JBN', 'DHN', 'RSN', 'AWAAN', 'BBAAN', 'DEN', 'AN', 'EKN', 'CWAAN', 'DSAAN', 'FJAAN', 'CLAAN', 'BUAAN', 'ELAAN', 'CJAAN', 'EYAAN', 'EN', 'HSN', 'UXN', 'UA', 'N'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tailnumbers = df_filters.filter(col('Column Name').isin(['TailNum'])).select('Non-arithmetic Values').collect()\n",
    "tailnumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'NA' in tailnumbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- TailNums are strings and not numbers.\n",
    "- We do not have any 'NA' tailnumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions and Code Steps:\n",
    "\n",
    "*Assumptions*\n",
    "- Each plane can be uniquely identified via its tail number.\n",
    "- Cancelled flights can be either filtered out or preserved in the dataset according to the application context. In this case, we chose to dicard them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Code*\n",
    " 1. **Filter**: We discard all cancelled flights using `.filter()`. Condition: `x[21] =='0'`.\n",
    " 2. **Map**: We map over tuples and create key-value pairs (Key= TailNum, value=1) using `.map()`. Our goal being to simply count the realized flights for each plane, we discard all other attributes to improve efficiency (less data to work with).\n",
    " 3. **Reduce**: We reduce the results by aggregating (here: adding) the 1s for each separate key using `reduceByKey()` and `add`.\n",
    " 4. **Sorting**: We use `sortBy()` to sort by the Number of Flights in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes_by_flights = data.filter(lambda x: x[21]=='0') \\\n",
    "                   .map(lambda x: (x[10],1)) \\\n",
    "                   .reduceByKey(add)\\\n",
    "                   .sortBy(lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are then summarised in the following table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|TailNum|Number of Flights|\n",
      "+-------+-----------------+\n",
      "| N655BR|             4457|\n",
      "| N479HA|             4359|\n",
      "| N651BR|             4324|\n",
      "| N478HA|             4316|\n",
      "| N654BR|             4252|\n",
      "| N480HA|             4225|\n",
      "| N485HA|             4203|\n",
      "| N484HA|             4126|\n",
      "| N693BR|             4088|\n",
      "| N481HA|             4045|\n",
      "| N487HA|             4038|\n",
      "| N477HA|             3958|\n",
      "| N810AL|             3939|\n",
      "| N837AL|             3881|\n",
      "| N475HA|             3854|\n",
      "| N486HA|             3820|\n",
      "| N476HA|             3685|\n",
      "| N836AL|             3680|\n",
      "| N808AL|             3676|\n",
      "| N824AL|             3672|\n",
      "| N646BR|             3502|\n",
      "| N828AL|             3493|\n",
      "| N295SW|             3466|\n",
      "| N226SW|             3462|\n",
      "| N835AL|             3440|\n",
      "| N292SW|             3437|\n",
      "| N220SW|             3435|\n",
      "| N295UX|             3426|\n",
      "| N234SW|             3365|\n",
      "| N294SW|             3321|\n",
      "| N250YV|             3303|\n",
      "| N218SW|             3285|\n",
      "| N393SW|             3271|\n",
      "| N290SW|             3265|\n",
      "| N293SW|             3229|\n",
      "| N227SW|             3215|\n",
      "| N251YV|             3209|\n",
      "| N221SW|             3204|\n",
      "| N233SW|             3186|\n",
      "| N821AL|             3184|\n",
      "| N229SW|             3181|\n",
      "| N308SW|             3178|\n",
      "| N235SW|             3172|\n",
      "| N223SW|             3152|\n",
      "| N562SW|             3127|\n",
      "| N289YV|             3082|\n",
      "| N284YV|             3069|\n",
      "| N297SW|             3051|\n",
      "| N576SW|             3047|\n",
      "| N568SW|             3024|\n",
      "| N560SW|             3021|\n",
      "| N578SW|             3009|\n",
      "| N823AL|             3008|\n",
      "| N567SW|             3008|\n",
      "| N291SW|             3006|\n",
      "| N301YV|             2952|\n",
      "| N299SW|             2916|\n",
      "| N564SW|             2907|\n",
      "| N292UX|             2872|\n",
      "| N583SW|             2858|\n",
      "| N566SW|             2848|\n",
      "| N236SW|             2844|\n",
      "| N224SW|             2843|\n",
      "| N585SW|             2841|\n",
      "| N288SW|             2827|\n",
      "| N582SW|             2813|\n",
      "| N270YV|             2811|\n",
      "| N563SW|             2810|\n",
      "| N569SW|             2799|\n",
      "| N584SW|             2777|\n",
      "| N455YV|             2765|\n",
      "| N271YV|             2764|\n",
      "| N565SW|             2761|\n",
      "| N296SW|             2753|\n",
      "| N586SW|             2751|\n",
      "| N217SW|             2712|\n",
      "| N639SW|             2692|\n",
      "| N379SW|             2690|\n",
      "| N384SW|             2689|\n",
      "| N215SW|             2687|\n",
      "| N695SW|             2684|\n",
      "| N622SW|             2681|\n",
      "| N635SW|             2672|\n",
      "| N448YV|             2669|\n",
      "| N625SW|             2667|\n",
      "| N624SW|             2666|\n",
      "| N634SW|             2665|\n",
      "| N385SW|             2663|\n",
      "| N629SW|             2660|\n",
      "| N632SW|             2658|\n",
      "| N628SW|             2657|\n",
      "| N621SW|             2656|\n",
      "| N580SW|             2655|\n",
      "| N636WN|             2655|\n",
      "| N389SW|             2652|\n",
      "| N581SW|             2652|\n",
      "| N579SW|             2652|\n",
      "| N561SW|             2652|\n",
      "| N309SW|             2651|\n",
      "| N627SW|             2644|\n",
      "+-------+-----------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = sqlContext.createDataFrame(planes_by_flights, ['TailNum', 'Number of Flights']).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 : Compute the total flight time of each airplane, sorted by flight time in descending order.\n",
    "\n",
    "Each airplane is uniquely identified via its Tail number (*TailNum*) as explained in Q3. Moreover, the flight time of each flight is captured in the attribute *ActualElapsedTime*, as indicated in the assignment clarification on Insendi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we make use of the columns:\n",
    "- *TailNum* (column 11)\n",
    "- *Cancelled* (column 22)\n",
    "- *ActualElapsedTime* (column 12)\n",
    "\n",
    "\n",
    "We only inspect the new columns. i.e. *ActualElapsedTime*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Non-arithmetic Values=['NA', 'ActualElapsedTime'])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AET = df_filters.filter(col('Column Name').isin(['ActualElapsedTime'])).select('Non-arithmetic Values').collect()\n",
    "AET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- *ActualElapsedTime* containts NA values.\n",
    "- *ActualElapsedTime* does not have any negative valus (no hyphens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions and Code Steps:\n",
    "\n",
    "*Assumptions*\n",
    "- Each plane can be uniquely identified via its tail number.\n",
    "- Cancelled flights should not be counted as flight time since the planes have not executed them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Code*\n",
    " 1. **Filter**: We discard all cancelled flights using `.filter()` and the condition: `x[21] =='0'`. We exclude NA values using `x[11]!= 'NA'`\n",
    " 2. **Map**: We map over tuples and create key-value pairs (Key= TailNum, value= float(*ActualElapsedTime*)) using `.map()`. No other attribute is required for the calculations.\n",
    " 3. **Reduce**: We reduce the results by aggregating (here: adding) the *ActualElapsedTime* values for each separate key using `reduceByKey()` and `add`.\n",
    " 4. **Sorting**: We use `sortBy()` to sort by the total flight time in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_time_by_plane = data.filter(lambda x: x[21]=='0' and x[11]!='NA') \\\n",
    "                           .map(lambda x: (x[10], float(x[11]))) \\\n",
    "                           .reduceByKey(add) \\\n",
    "                           .sortBy(lambda x:-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|TailNum|Flight time|\n",
      "+-------+-----------+\n",
      "| N556AS|   592470.0|\n",
      "| N637JB|   296443.0|\n",
      "| N636JB|   296091.0|\n",
      "| N646JB|   293882.0|\n",
      "| N607JB|   293853.0|\n",
      "| N624JB|   292416.0|\n",
      "| N599JB|   291035.0|\n",
      "| N640JB|   290752.0|\n",
      "| N590NW|   290597.0|\n",
      "| N625JB|   290284.0|\n",
      "| N639JB|   289787.0|\n",
      "| N557UA|   289540.0|\n",
      "| N649JB|   289044.0|\n",
      "| N618JB|   288891.0|\n",
      "| N645JB|   288835.0|\n",
      "| N523JB|   287243.0|\n",
      "| N524JB|   286692.0|\n",
      "| N634JB|   286676.0|\n",
      "| N630JB|   286470.0|\n",
      "| N633JB|   286107.0|\n",
      "| N621JB|   285990.0|\n",
      "| N638JB|   285929.0|\n",
      "| N579JB|   285598.0|\n",
      "| N632JB|   285468.0|\n",
      "| N597UA|   285104.0|\n",
      "| N641JB|   284748.0|\n",
      "| N520JB|   284729.0|\n",
      "| N629JB|   284394.0|\n",
      "| N623JB|   284146.0|\n",
      "| N603JB|   283655.0|\n",
      "| N613JB|   283401.0|\n",
      "| N585JB|   283278.0|\n",
      "| N608JB|   283055.0|\n",
      "| N590UA|   283007.0|\n",
      "| N569JB|   282939.0|\n",
      "| N558AS|   281977.0|\n",
      "| N585NW|   281768.0|\n",
      "| N648JB|   281498.0|\n",
      "| N587JB|   281450.0|\n",
      "| N582NW|   281266.0|\n",
      "| N505UA|   281144.0|\n",
      "| N592JB|   281092.0|\n",
      "| N589JB|   281092.0|\n",
      "| N554UA|   280918.0|\n",
      "| N588JB|   280903.0|\n",
      "| N591NW|   280710.0|\n",
      "| N598UA|   280574.0|\n",
      "| N564JB|   280260.0|\n",
      "| N590JB|   280146.0|\n",
      "| N593NW|   280142.0|\n",
      "| N644JB|   280112.0|\n",
      "| N591JB|   280087.0|\n",
      "| N606JB|   279468.0|\n",
      "| N584NW|   279081.0|\n",
      "| N612JB|   278979.0|\n",
      "| N547JB|   278681.0|\n",
      "| N643JB|   278657.0|\n",
      "| N594NW|   278489.0|\n",
      "| N543UA|   278422.0|\n",
      "| N565AS|   278106.0|\n",
      "| N593JB|   278010.0|\n",
      "| N595UA|   277966.0|\n",
      "| N581JB|   277860.0|\n",
      "| N565JB|   277602.0|\n",
      "| N605JB|   276700.0|\n",
      "| N615JB|   276569.0|\n",
      "| N537JB|   276333.0|\n",
      "| N571JB|   276242.0|\n",
      "| N592NW|   276241.0|\n",
      "| N589UA|   276143.0|\n",
      "| N627JB|   276097.0|\n",
      "| N584JB|   276074.0|\n",
      "| N504JB|   276029.0|\n",
      "| N546JB|   275936.0|\n",
      "| N586JB|   275876.0|\n",
      "| N588NW|   275704.0|\n",
      "| N554JB|   275668.0|\n",
      "| N582JB|   275290.0|\n",
      "| N666UA|   275214.0|\n",
      "| N566JB|   275086.0|\n",
      "| N583NW|   274974.0|\n",
      "| N601AW|   274277.0|\n",
      "| N549UA|   274175.0|\n",
      "| N553JB|   274144.0|\n",
      "| N597JB|   274095.0|\n",
      "| N560UA|   273642.0|\n",
      "| N595NW|   273215.0|\n",
      "| N596UA|   273209.0|\n",
      "| N587NW|   273112.0|\n",
      "| N550JB|   272980.0|\n",
      "| N598JB|   272406.0|\n",
      "| N589NW|   272277.0|\n",
      "| N534JB|   272205.0|\n",
      "| N548JB|   271732.0|\n",
      "| N212UA|   271674.0|\n",
      "| N562JB|   271478.0|\n",
      "| N568JB|   271296.0|\n",
      "| N551AS|   271250.0|\n",
      "| N536JB|   271085.0|\n",
      "| N635JB|   270912.0|\n",
      "+-------+-----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = sqlContext.createDataFrame(flight_time_by_plane, ['TailNum', 'Flight time']).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Important Note*  \n",
    "Inspecting the table, we easily observe that the total flight time of the first airplane (\\~60K minutes) is double that of the second (\\~30K minutes). On top of that, simply by googling, we realize that one year has less than 60K minutes which hints at the fact that some sort of mistake has been made when tabling the data for the plane N556AS. Thus, in the absence of further information, we should not regard that result for the first plane as accurate, until more information comes to light. The remaining 99 planes previewed on the table have much more similar flight times, indicatung that the results are probably accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 : Find the busiest airport (in terms of number of departures + arrivals of all operated flights) for each month.\n",
    "\n",
    "An airport is uniquely identified through its IATA code airport code. Each record in the data set entails information about the origin airport (column:Origin) and destination airport (column:Dest) of the flight. As per instruction, we are consdering only the operated flights, i.e., we will filter out the cancelled ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we make use of the columns:\n",
    "- *Origin* (column 17)\n",
    "- *Dest* (column 18)\n",
    "- *Cancelled* (column 22)\n",
    "\n",
    "The new columns are both strings with coded information, we cannot easily check for mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions and Code Steps:\n",
    "\n",
    "*Assumptions*\n",
    "- Each airport can be uniquely identified through its IATA code.\n",
    "- Cancelled flights should not be counted as flight time since the planes have not executed them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Code*\n",
    " 1. **Filter**: We discard all cancelled flights using `.filter()` and the condition: `x[21] =='0'`.\n",
    " 2. **Map**: We use `.flatMap()` to create key-value pairs (Key= (Month, Airport), Value= 1) for each of the destination and origin airport values contained in the record.\n",
    " 3. **Reduce**: We reduce the results by aggregating (here: adding) the 1s for separate keys using `reduceByKey()` and `add`. Each reducer handles one Month-Airport combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "busiest_airports = data.filter(lambda x: x[21]=='0')\\\n",
    "                       .flatMap(lambda x: (((int(x[1]), x[16]), 1),(((int(x[1]), x[17]), 1))))\\\n",
    "                       .reduceByKey(add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We define a custom funtion `find_max()` to select the airport with the highest amount of incoming/outgoing flights for each month. The function:\n",
    "    - takes two tuples as input (typical `reduce` syntax) of the form (Airline, Number of fights)\n",
    "    - finds the maximum number of flights out of the two, and returns the Airline and the max Number of flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(x,y):\n",
    "    b = max(x[1],y[1])\n",
    "    if b == x[1]:\n",
    "        a = x[0]\n",
    "    else:\n",
    "        a = y[0]\n",
    "    return (a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. We remap and use our custom function within the `.reduceByKey()`function to find the airport with the highest traffic for each month.\n",
    "6. We sort by key(=month) using `.sortByKey()`.\n",
    "7. We remap the tuples for easier printing of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "busiest_airports_ordered = busiest_airports.map(lambda x: (x[0][0], (x[0][1],x[1])))\\\n",
    "                                           .reduceByKey(find_max)\\\n",
    "                                           .sortByKey()\\\n",
    "                                           .map(lambda x: (x[0], x[1][0], x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = sqlContext.createDataFrame(busiest_airports_ordered, ['Month','Airport','Number of Flights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be seen below. Atlanta's airport exhibits constantly the highest traffic throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----------------+\n",
      "|Month|Airport|Number of Flights|\n",
      "+-----+-------+-----------------+\n",
      "|    1|    ATL|            62955|\n",
      "|    2|    ATL|            57654|\n",
      "|    3|    ATL|            66750|\n",
      "|    4|    ATL|            64953|\n",
      "|    5|    ATL|            68000|\n",
      "|    6|    ATL|            70168|\n",
      "|    7|    ATL|            72327|\n",
      "|    8|    ATL|            72850|\n",
      "|    9|    ATL|            67732|\n",
      "|   10|    ATL|            73126|\n",
      "|   11|    ATL|            68883|\n",
      "|   12|    ATL|            67674|\n",
      "+-----+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 : Find the airline with highest average delay of each type in March 2007.\n",
    "\n",
    "*Note: do not write separate code for each error type. You should compute a single RDD where each row contains the delay type, the airline that is worst regarding that delay type, and its average delay of that type in minutes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we make use of the columns:\n",
    "\n",
    "\n",
    "- *ArrDelay* (column15)\n",
    "- *DepDelay* (column16)\n",
    "- *CarrierDelay* (column(25)\n",
    "- *WeatherDelay* (column26)\n",
    "- *NASDelay* (column 27)\n",
    "- *SecurityDelay* (column28)\n",
    "- *LateAircraftDelay* (column 29)\n",
    "- *Cancelled* (column 22)\n",
    "\n",
    "Let's inspect the delay values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Non-arithmetic Values=['WeatherDelay']),\n",
       " Row(Non-arithmetic Values=['NA-', 'NA', 'ArrDelay', '-']),\n",
       " Row(Non-arithmetic Values=['NASDelay']),\n",
       " Row(Non-arithmetic Values=['SecurityDelay']),\n",
       " Row(Non-arithmetic Values=['LateAircraftDelay']),\n",
       " Row(Non-arithmetic Values=['-', 'NA-', 'NA', 'DepDelay']),\n",
       " Row(Non-arithmetic Values=['CarrierDelay'])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filters.filter(col('Column Name').isin(['ArrDelay', 'DepDelay', 'CarrierDelay', 'WeatherDelay',\n",
    "                                           'NASDelay', 'SecurityDelay', 'LateAircraftDelay'])).select('Non-arithmetic Values').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- *ArrDelay* and *DepDelay* contain both negative values (hyphens) as well as NAs. They are the only ones that need filtering out.\n",
    "- The remaining delay columns have neither negative values nor NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions and Code Steps:\n",
    "\n",
    "*Assumptions*\n",
    "- We filter out negative delays as they can skew the results. Flying earlier might be convenient, but passangers are usually concerned with the average delays when there are indeed delays. We thus find it more insightful to filter out negative delays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Code*\n",
    " 1. **Filter**: We use `.filter()` to:\n",
    "     - Discard all cancelled flights  `x[21] =='0'`.\n",
    "     - Select only data from March `Month == '3'`.\n",
    "     - Filter out NAs (e.g., `ArrDelay!='NA'`) and  negative values (e.g., `float(ArrDelay)>=0`).  \n",
    "  \n",
    "  \n",
    "   \n",
    "2. **Map**: We use `.flatMap()` to create separate key-value pairs of the form\n",
    "    - (Key= (Airline, DelayType), Value = (Delay-value, 1)).\n",
    " 3. **Reduce**: We reduce the results by aggregating (here: adding) the values for each  delay type and counting the total number of flights for each Airline-Delay type combination (each reducer handles data for one such combination). We aggregate using `reduceByKey()` and using a lambda expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delays = data.filter(lambda x: x[1]=='3' and x[21]=='0'\n",
    "                             and x[14]!='NA' and float(x[14])>=0\n",
    "                             and x[15]!='NA' and float(x[15])>=0)\\\n",
    "\\\n",
    "                     .flatMap(lambda x: (((x[8],\"ArrDelay\"), (x[14],1)), \n",
    "                                     ((x[8], \"DepDelay\"), (x[15],1)), \n",
    "                                     ((x[8], \"CarrierDelay\"), (x[24],1)), \n",
    "                                     ((x[8], \"WeatherDelay\"), (x[25],1)), \n",
    "                                     ((x[8], \"NASDelay\"), (x[26],1)), \n",
    "                                     ((x[8], \"SecurityDelay\"), (x[27],1)),\n",
    "                                     ((x[8], \"LateAircraftDelay\"), (x[28],1))))\\\n",
    "\\\n",
    "                     .reduceByKey(lambda x,y : (float(x[0]) + float(y[0]), x[1]+y[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We remap the tuples such that they take the assume the form (Key:(Airline, DelayType), Value:(Average delay)) using `.map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delays2 = airline_delays.map(lambda x: ((x[0][0],x[0][1]), x[1][0]/x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. We reduce the results by finding the maximum average delay for each delay type using `.reduceByKey()` with our custom function `find_max()` as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delays3 = airline_delays2.map(lambda x: (x[0][1], (x[0][0],round(x[1],3))))\\\n",
    "                                 .reduceByKey(find_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. We remap for easier printing: the tuple takes the form: (delay type, airline, average delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delays4 = airline_delays3.map(lambda x: (x[0], x[1][0], x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+-------------+\n",
      "|        DelayType|Airlines|Average Delay|\n",
      "+-----------------+--------+-------------+\n",
      "|     WeatherDelay|      OH|        6.014|\n",
      "|         ArrDelay|      XE|       52.735|\n",
      "|         NASDelay|      CO|       16.745|\n",
      "|    SecurityDelay|      AQ|        0.333|\n",
      "|LateAircraftDelay|      B6|        22.13|\n",
      "|         DepDelay|      XE|       49.326|\n",
      "|     CarrierDelay|      EV|       20.649|\n",
      "+-----------------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6 = sqlContext.createDataFrame(airline_delays4, ['DelayType', 'Airlines', 'Average Delay']).show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 : Compute median, mean, and mode of columns 12-16, 19-21 and 25-29 for the flights in the third week of 2007.\n",
    "*Note: Exclude the non-numeric values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we make use of the columns:\n",
    "\n",
    "- *ActualElapsedTime* (column 12)\n",
    "- *CRSElapsedTime*  (column 13)\n",
    "- *AirTime* (column 14)\n",
    "- *Distance* (column 19)\n",
    "- *TaxiIn* (column 20)\n",
    "- *TaxiOut* (column 21)\n",
    "-  Delay types (columns 15-16, 25-29)\n",
    "\n",
    "The new columns will be inspected below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Non-arithmetic Values=['-', 'NA', 'CRSElapsedTime']),\n",
       " Row(Non-arithmetic Values=['TaxiOut']),\n",
       " Row(Non-arithmetic Values=['Distance']),\n",
       " Row(Non-arithmetic Values=['TaxiIn']),\n",
       " Row(Non-arithmetic Values=['AirTime', 'NA'])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filters.filter(col('Column Name').isin(['CRSElapsedTime', 'AirTime', 'Distance', 'TaxiIn',\n",
    "                                           'TaxiOut'])).select('Non-arithmetic Values').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- *CRSElapsedTime* contains both negative values (hyphens) as well as NAs. These need filtering out.\n",
    "- *TaxiOut*, *TaxiIn* and *Distance* have neither negative values nor NAs.\n",
    "- *AirTime* has NA values that need filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions and Code Steps:\n",
    "\n",
    "*Assumptions*\n",
    "- No specific assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Code*\n",
    " 1. **Filter**: We use `.filter()` to:\n",
    "     - Select only data from January: `Month == '1'`.\n",
    "     - Select only the third week from January: `int(Day) >=15 and int(Day)<=21`\n",
    "     - Filter out NAs (e.g., `ArrDelay!='NA'`) and  negative values (e.g., `float(ArrDelay)>=0`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataq7 = data.filter(lambda x: x[1]=='1' and int(x[2])>=15 and int(x[2])<=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataq7 = dataq7.filter(lambda x: \n",
    "                 x[11]!= 'NA' and                       #ActualElapsedTime\n",
    "                 x[12]!= 'NA' and float(x[12])>=0 and   #CRSElapsedTime\n",
    "                 x[13]!= 'NA' and                       #Airtime  \n",
    "                 x[14]!= 'NA' and float(x[14])>=0 and   #ArrDelay\n",
    "                 x[15]!= 'NA' and float(x[15])>=0)      #DepDelay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Create a custom function `calculate_statistics`**: We create a function that:\n",
    "     - takes a list-type object of numbers as input:\n",
    "     - calculates the median, mean and mode of those numbers\n",
    "     - outputs the median, mean and mode as a tuple (median, mean, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(list_of_numbers):\n",
    "    import statistics\n",
    "    delay_median = statistics.median(list_of_numbers)\n",
    "    delay_mean = statistics.mean(list_of_numbers)\n",
    "    delay_mode = statistics.mode(list_of_numbers)\n",
    "    return (delay_median, delay_mean, delay_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Map**: We use `.flatMap()` to:\n",
    "     - create a new row for each of the columns we would like to compute statistics for\n",
    "4. **Aggregate/Reduce**: We use `.groupByKey()` to get all values for each column in a list-type object\n",
    "5. **Map the values to our custom function**: We employ `.mapValues()` to\n",
    "    - send the list of values of each column to a reducer\n",
    "    - the reducer uses our custom function `calculate_statistics()` to return a tuple with the median, mean, mode for each column\n",
    "6. **Remap the values for printing purposes**: We use `.map()` to rearrange the terms - makes it easier to preview as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_statistics  = dataq7.flatMap(lambda x:(\n",
    "                               ('ActualElapsedTime', float(x[11])),\n",
    "                               ('CRSElapsedTime'   , float(x[12])),\n",
    "                               ('AirTime'          , float(x[13])),\n",
    "                               ('ArrDelay'         , float(x[14])),\n",
    "                               ('DepDelay'         , float(x[15])),\n",
    "                               ('Distance'         , float(x[18])),\n",
    "                               ('TaxiIn'           , float(x[19])),\n",
    "                               ('TaxiOut'          , float(x[20])),\n",
    "                               ('CarrierDelay'     , float(x[24])),\n",
    "                               ('WeatherDelay'     , float(x[25])),\n",
    "                               ('NASDelay'         , float(x[26])),\n",
    "                               ('SecurityDelay'    , float(x[27])),\n",
    "                               ('LateAircraftDelay', float(x[28]))))\\\n",
    "            .groupByKey()\\\n",
    "            .mapValues(calculate_statistics)\\\n",
    "            .map(lambda x: (x[0], x[1][0], round(x[1][1],3), x[1][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting table can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+-------+-----+\n",
      "|      Column Name|Median|   Mean| Mode|\n",
      "+-----------------+------+-------+-----+\n",
      "|     WeatherDelay|   0.0|  3.979|  0.0|\n",
      "|   CRSElapsedTime| 109.0|125.735| 75.0|\n",
      "|ActualElapsedTime| 114.0|131.264| 80.0|\n",
      "|          TaxiOut|  16.0| 21.318| 10.0|\n",
      "|         ArrDelay|  26.0| 43.785|  0.0|\n",
      "|         NASDelay|   0.0| 10.966|  0.0|\n",
      "|    SecurityDelay|   0.0|  0.028|  0.0|\n",
      "|         Distance| 556.0|697.689|370.0|\n",
      "|           TaxiIn|   6.0|  7.527|  4.0|\n",
      "|LateAircraftDelay|   0.0|  16.99|  0.0|\n",
      "|         DepDelay|  21.0| 38.255|  0.0|\n",
      "|          AirTime|  85.0| 102.42| 59.0|\n",
      "|     CarrierDelay|   0.0|  9.656|  0.0|\n",
      "+-----------------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7 = sqlContext.createDataFrame(column_statistics, ['Column Name', 'Median', 'Mean', 'Mode']).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8 :Assume that a passenger wants to travel from Philadelphia International Airport (airport code:PHL) to Los Angeles International Airport (airport code: LAX), and then go back to Philadelphia (PHL). He departs PHL not earlier than 5:59 am (scheduled time), stays at least 3:01 hours in Los Angeles and then arrives at PHL not later than 11pm. Based on the \"scheduled\" times, find which carrier has the highest number of flights with these constraints. Limit your analysis to February 2007 and use scheduled times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use columns:\n",
    "- *Month*  (column 2)\n",
    "- *Origin* (column 17)\n",
    "- *Dest*   (column 18)\n",
    "- *CRSDepTime* (column 6)\n",
    "- *CRSArrTime* (column 8)\n",
    "- *UniqueCarrier* (column 9)\n",
    "\n",
    "We have inspected all columns in previous steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions and Code Steps:\n",
    "\n",
    "*Assumptions*\n",
    "-  We do not take indirect flights into account\n",
    "-  We will base our analysis on round-trips; one flight is counted when a company offers a full trip i.e., both a go-to and return flight satisfying the given constraints.\n",
    "-  We do take cancelled flights into account. Flights get cancelled for unsystematic reasons. If we want to use the data from Februrary 2007 as an indication for the number of  round-trips available in the next year, factoring in the flights that were scheduled but got randomly cancelled would give us a better overview of the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Code*\n",
    " 1. **Filter**: We use `.filter()` to:\n",
    "     - Select only data from February: `Month == '2'`.\n",
    "     - Create two RDDs where:\n",
    "         - The 1st RDD(PHL_LAX_departures) contains all flights from PHL TO LAX that depart after 05:59 am AND where the departure time is less than the arrival time - filters out overnight flights.\n",
    "         - The 2rd RDD(LAX_PHL_departures) contains all flights from LAX to PHL that arrive in Philadelphia before 23.00 AND where the departure time is less than the arrival time - filters out overnight flights.\n",
    "2. **Map** We use `.map()` to:\n",
    "    - create (key, value) pairs of the form (Key = (Carrier, Day of the Month), Value = (Departure Time, Arrival Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataq8 = data.filter(lambda x: x[1]=='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHL_LAX_departures =  dataq8.filter(lambda x: (x[16]=='PHL' and x[17]=='LAX' and int(x[5])>= 559 and (int(x[5]) <= int(x[7]))))\\\n",
    "                            .map(lambda x: ((x[8], int(x[2])), (int(x[5]),int(x[7]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAX_PHL_departures =  dataq8.filter(lambda x: (x[16]=='LAX' and x[17]=='PHL' and int(x[7])<=2300 and (int(x[5]) <= int(x[7]))))\\\n",
    "                            .map(lambda x: ((x[8], int(x[2])), (int(x[5]), int(x[7]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Merge Datasets and Filter** : We use `.join()` to merge the datasets that:\n",
    "    - are joined according to keys, i.e., each row is a combination of go-to and return flights from the same airline and on the same day.\n",
    "    - satisfy the additional condition that the arrival time in LAX and the departure time from LAX have at least a difference of 3.01 hours - (we use `.filter()`)\n",
    "    \n",
    "The resulting dataset contains all relevant combinations of flights for each day in February and for each airline.\n",
    "\n",
    "4. **We remap the values for nice printing**: We use `.map()` to format each tuple as (key, value1, value2,...)\n",
    "5. **Sort the values by day for nice printing**: We sort by day in ascending order using `sortBy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_trips = PHL_LAX_departures.join(LAX_PHL_departures)\\\n",
    "                                .filter(lambda x: (x[1][1][0] - x[1][0][1])>= 301)\\\n",
    "                                .map(lambda x: (x[0][0], x[0][1], x[1][0][0], x[1][0][1], x[1][1][0], x[1][1][1]))\\\n",
    "                                .sortBy(lambda x: int(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------------+-----------+-------------+-----------+\n",
      "|Airline|Day|PHL Departure|LAX Arrival|LAX Departure|PHL Arrival|\n",
      "+-------+---+-------------+-----------+-------------+-----------+\n",
      "|     UA| 14|          700|       1001|         1353|       2153|\n",
      "|     UA| 15|          700|       1001|         1353|       2153|\n",
      "|     UA| 16|          700|       1001|         1353|       2153|\n",
      "|     UA| 17|          700|       1001|         1353|       2153|\n",
      "|     UA| 18|          700|       1001|         1353|       2153|\n",
      "|     UA| 19|          700|       1001|         1353|       2153|\n",
      "|     UA| 20|          700|       1001|         1353|       2153|\n",
      "|     UA| 21|          700|       1001|         1353|       2153|\n",
      "|     UA| 22|          700|       1001|         1353|       2153|\n",
      "|     UA| 23|          700|       1001|         1353|       2153|\n",
      "|     UA| 24|          700|       1001|         1353|       2153|\n",
      "|     UA| 25|          700|       1001|         1353|       2153|\n",
      "|     UA| 26|          700|       1001|         1353|       2153|\n",
      "|     UA| 27|          700|       1001|         1353|       2153|\n",
      "|     UA| 28|          700|       1001|         1353|       2153|\n",
      "+-------+---+-------------+-----------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_round_trips = sqlContext.createDataFrame(round_trips, ['Airline', 'Day', 'PHL Departure', 'LAX Arrival', \n",
    "                                                         'LAX Departure', 'PHL Arrival']).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a quick look at the table, it becomes clear that \"UA\" is the only airline that offered flights from PHL to LAX and back in February 2007 that met the specified constraints. In particular, said flights were scheduled daily, from the 14th of February until the end of the month. Inspection of the arrival and departure times lays bear that it is indeed the same flight (same schedule) every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many flights in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_trips.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 15 round trips scheduled in February 2007 meeting those constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9 : Generate the *departure flights* board of the Los Angeles Airport at 12 Jan 2007 at 13:00. The board should contain flights with actual departure times between 12:00 and 14:00, sorted by scheduled departure time. The resulting table should at least contain scheduled departure time, actual departure time (if departed), airline code, and destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use columns:\n",
    "\n",
    "- *Month* (column 2)\n",
    "- *Day* (column 3)\n",
    "- *DepTime*(column 5)\n",
    "- *CRSDepTime* (column 6)\n",
    "- *UniqueCarrier* (column 9)\n",
    "- *Origin* (column 17)\n",
    "- *Dest* (column 18)\n",
    "\n",
    "*DepTime* is to be inspected. (The remaining columns have been inspected before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Non-arithmetic Values=['NA', 'DepTime'])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filters.filter(col('Column Name').isin(['DepTime'])).select('Non-arithmetic Values').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- *DepTime* contains NA values that require filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions and Code Steps:\n",
    "\n",
    "*Assumptions*\n",
    "-  We inspect the dataset to find whether there are cancelled flights on the day. There are none.\n",
    "-  For flights that had departed by 13.00 we preview the actual departure time and for those that departed later, we use a hyphen (-)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigation of cancelled flights on the day - `x[21]=='1'` (for more filtering information, please see the next code snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataq9_cancelled = data.filter(lambda x: x[1]=='1'\n",
    "                     and x[2]=='12'\n",
    "                     and x[16]=='LAX'\n",
    "                     and x[4]!='NA'\n",
    "                     and x[21]=='1')\\\n",
    "                      .map(lambda x: (x[4], x[5]))\\\n",
    "                      .collect()\n",
    "        \n",
    "len(dataq9_cancelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No cancelled flights on the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Code*\n",
    " 1. **Filter**: We use `.filter()` to:\n",
    "     - Select only data from January: `Month == '1'`.\n",
    "     - Select only data from the 12th of January: `Day=='12'`.\n",
    "     - Select only the LAX airport: `Origin='LAX'`\n",
    "     - Filter out NA values from *DepTime* : `DepTime!='NA'`.\n",
    "     - Select only flights with actual departure time between 12.00 and 14.00: `1200 <= DepTime <= 1400`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataq9 = data.filter(lambda x: x[1]=='1'\n",
    "                     and x[2]=='12'\n",
    "                     and x[16]=='LAX'\n",
    "                     and x[4]!='NA'\n",
    "                     and (int(x[4])>=1200 and int(x[4])<=1400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Use map with our custom function `map9()`**: We a build a function that:\n",
    "    - takes a tuple as input a full row from the data\n",
    "    - outputs a tuple that contains\n",
    "        - the scheduled departure time as key\n",
    "        - a tuple of values (actual departure time/hyphen, carrier, destination)\n",
    "    \n",
    "We use the `.map()` function with `map9()` as argument to map the tuples to the form (Key:Scheduled Departure Time, Value: (Actual Departure Time/Hyphen, Carrier, Destination ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map9(x):\n",
    "    if int(x[4])<=1300:\n",
    "        dep = x[4]\n",
    "    else:\n",
    "        dep = '-'\n",
    "    return (int(x[5]), (dep, x[8], x[17]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Sort**: We sort by key (`sortByKey()`), i.e., the Scheduled Departure Time, as requested.\n",
    "4. **Remap the values for easy printing** using `.map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "departure_table = dataq9.map(map9)\\\n",
    "                        .sortByKey()\\\n",
    "                        .map(lambda x: (x[0], x[1][0], x[1][1], x[1][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can bee seen below (only the 100 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+---------------------+-------+-----------+\n",
      "|Scheduled Departure Time|Actual Departure Time|Carrier|Destination|\n",
      "+------------------------+---------------------+-------+-----------+\n",
      "|                    1100|                 1208|     UA|        ORD|\n",
      "|                    1140|                 1218|     OO|        OXR|\n",
      "|                    1140|                 1202|     AA|        DFW|\n",
      "|                    1142|                 1206|     DL|        CVG|\n",
      "|                    1145|                 1210|     WN|        SLC|\n",
      "|                    1155|                 1252|     MQ|        SJC|\n",
      "|                    1155|                 1242|     AA|        LAS|\n",
      "|                    1157|                 1216|     OO|        PSP|\n",
      "|                    1200|                 1256|     WN|        OAK|\n",
      "|                    1200|                 1213|     CO|        IAH|\n",
      "|                    1205|                 1206|     AA|        MIA|\n",
      "|                    1211|                 1254|     NW|        MSP|\n",
      "|                    1214|                 1217|     OO|        SAN|\n",
      "|                    1215|                 1213|     WN|        SJC|\n",
      "|                    1215|                 1217|     DL|        ATL|\n",
      "|                    1220|                 1216|     FL|        ATL|\n",
      "|                    1220|                 1215|     MQ|        MRY|\n",
      "|                    1224|                 1224|     OO|        SJC|\n",
      "|                    1224|                 1219|     UA|        SFO|\n",
      "|                    1225|                 1226|     OO|        OAK|\n",
      "|                    1229|                 1229|     OO|        SAN|\n",
      "|                    1229|                 1250|     UA|        DEN|\n",
      "|                    1230|                 1252|     WN|        LAS|\n",
      "|                    1230|                 1243|     NW|        DTW|\n",
      "|                    1231|                 1245|     US|        LAS|\n",
      "|                    1235|                 1247|     WN|        BWI|\n",
      "|                    1235|                 1255|     WN|        MDW|\n",
      "|                    1235|                    -|     AS|        SEA|\n",
      "|                    1235|                 1228|     CO|        IAH|\n",
      "|                    1238|                 1241|     OO|        SMX|\n",
      "|                    1240|                 1239|     WN|        ELP|\n",
      "|                    1240|                 1236|     UA|        PDX|\n",
      "|                    1240|                 1246|     UA|        LAS|\n",
      "|                    1240|                 1252|     US|        PHL|\n",
      "|                    1240|                 1254|     AA|        DEN|\n",
      "|                    1244|                 1242|     OO|        MRY|\n",
      "|                    1244|                 1247|     OO|        SBA|\n",
      "|                    1245|                    -|     WN|        MCI|\n",
      "|                    1245|                 1253|     UA|        IAD|\n",
      "|                    1245|                 1246|     US|        PHX|\n",
      "|                    1245|                 1248|     US|        PHX|\n",
      "|                    1245|                 1244|     MQ|        SBP|\n",
      "|                    1245|                 1245|     MQ|        SAN|\n",
      "|                    1245|                 1242|     DL|        CVG|\n",
      "|                    1246|                 1236|     AS|        DCA|\n",
      "|                    1250|                    -|     OO|        PHX|\n",
      "|                    1250|                    -|     NW|        MEM|\n",
      "|                    1250|                 1300|     AA|        BOS|\n",
      "|                    1250|                    -|     AA|        DFW|\n",
      "|                    1255|                 1256|     WN|        SJC|\n",
      "|                    1255|                 1253|     UA|        BOS|\n",
      "|                    1255|                    -|     UA|        SFO|\n",
      "|                    1255|                    -|     MQ|        FAT|\n",
      "|                    1255|                    -|     AA|        SFO|\n",
      "|                    1259|                    -|     OO|        SAN|\n",
      "|                    1259|                    -|     DL|        JFK|\n",
      "|                    1300|                    -|     WN|        OAK|\n",
      "|                    1300|                    -|     OO|        RNO|\n",
      "|                    1300|                    -|     UA|        HNL|\n",
      "|                    1300|                    -|     UA|        ORD|\n",
      "|                    1300|                    -|     CO|        EWR|\n",
      "|                    1305|                    -|     WN|        ABQ|\n",
      "|                    1310|                    -|     WN|        PHX|\n",
      "|                    1310|                    -|     UA|        DFW|\n",
      "|                    1310|                    -|     US|        CLT|\n",
      "|                    1315|                    -|     OO|        ONT|\n",
      "|                    1315|                    -|     UA|        JFK|\n",
      "|                    1315|                    -|     MQ|        SBA|\n",
      "|                    1319|                    -|     OO|        SMF|\n",
      "|                    1320|                    -|     UA|        LIH|\n",
      "|                    1320|                    -|     AA|        JFK|\n",
      "|                    1325|                    -|     MQ|        LAS|\n",
      "|                    1325|                    -|     AA|        MIA|\n",
      "|                    1328|                    -|     OO|        SBP|\n",
      "|                    1330|                    -|     MQ|        SJC|\n",
      "|                    1334|                    -|     OO|        ABQ|\n",
      "|                    1335|                    -|     WN|        PHL|\n",
      "|                    1335|                    -|     WN|        SMF|\n",
      "|                    1335|                    -|     DL|        SLC|\n",
      "|                    1337|                    -|     OO|        SGU|\n",
      "|                    1340|                    -|     F9|        SFO|\n",
      "|                    1340|                    -|     MQ|        SAN|\n",
      "|                    1343|                    -|     OO|        COS|\n",
      "|                    1345|                    -|     OO|        CLD|\n",
      "|                    1345|                    -|     OO|        BFL|\n",
      "|                    1345|                    -|     AA|        AUS|\n",
      "|                    1345|                    -|     AA|        DFW|\n",
      "|                    1351|                    -|     UA|        SFO|\n",
      "|                    1405|                    -|     OO|        SAN|\n",
      "+------------------------+---------------------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df9 = sqlContext.createDataFrame(departure_table, ['Scheduled Departure Time', 'Actual Departure Time', 'Carrier', 'Destination']).show(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
